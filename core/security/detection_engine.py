"""
통합 보안 탐지 엔진

API 로그 이상 탐지와 네트워크 공격 탐지를 통합한 범용 탐지 시스템
- API 로그 기반 이상 탐지 (하이브리드 딥러닝 모델)
- 네트워크 트래픽 기반 공격 탐지 (일반 ML 모델)
- 실시간 모니터링 및 알림 시스템
- 성능 평가 및 시뮬레이션 기능
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import keras
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import joblib
import json
import time
import random
from datetime import datetime, timedelta
import re
from typing import Dict, List, Tuple, Optional, Any, Union
import warnings
warnings.filterwarnings('ignore')

# 설정 파일에서 가져오기
from config.settings import SecurityConfig
from config.logging import setup_logger
from utils.exceptions import SecurityDetectionError

logger = setup_logger(__name__)

# 랜덤 시드 설정
keras.utils.set_random_seed(SecurityConfig.RANDOM_SEED)
tf.config.experimental.enable_op_determinism()


class UnifiedDetectionEngine:
    """통합 보안 탐지 엔진"""
    
    def __init__(self, detection_type: str = 'api_log', model_type: str = 'hybrid'):
        """
        Args:
            detection_type: 'api_log' (API 로그 탐지) 또는 'network_traffic' (네트워크 트래픽 탐지)
            model_type: 'mlp', 'cnn', 'hybrid' (API 로그), 또는 'general' (네트워크)
        """
        self.detection_type = detection_type
        self.model_type = model_type
        
        # 모델 인스턴스들
        self.mlp_model = None
        self.cnn_model = None
        self.ensemble_model = None
        self.general_model = None
        
        # 전처리 도구들
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
        # 상태 변수들
        self.feature_names = []
        self.is_trained = False
        self.sequence_length = SecurityConfig.CNN_SEQUENCE_LENGTH
        
        # 탐지 이력
        self.detection_history = []
        self.alert_count = 0
        
        logger.info(f\"통합 탐지 엔진 초기화: {detection_type}, {model_type}\")\n    \n    def set_external_model(self, model, scaler=None):\n        \"\"\"외부 모델 설정 (네트워크 트래픽용)\"\"\"\n        self.general_model = model\n        if scaler:\n            self.scaler = scaler\n        logger.info(\"외부 모델 설정 완료\")\n    \n    def extract_api_features(self, log_entry: Dict) -> np.ndarray:\n        \"\"\"API 로그에서 특성 추출\"\"\"\n        try:\n            features = {}\n            \n            # 시간 기반 특성\n            timestamp = datetime.fromisoformat(log_entry.get('timestamp', datetime.now().isoformat()))\n            features['hour'] = timestamp.hour\n            features['day_of_week'] = timestamp.weekday()\n            features['is_weekend'] = 1 if timestamp.weekday() >= SecurityConfig.WEEKEND_THRESHOLD else 0\n            features['is_business_hour'] = 1 if SecurityConfig.BUSINESS_HOUR_START <= timestamp.hour <= SecurityConfig.BUSINESS_HOUR_END else 0\n            \n            # 요청 빈도 특성\n            features['requests_per_minute'] = log_entry.get('requests_per_minute', 0)\n            \n            # 요청 크기 특성\n            features['request_size'] = log_entry.get('request_size', 0)\n            features['content_length'] = int(log_entry.get('content_length', 0))\n            \n            # HTTP 메서드 원핫 인코딩\n            method = log_entry.get('method', 'GET')\n            for m in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:\n                features[f'method_{m}'] = 1 if method == m else 0\n            \n            # User-Agent 분석\n            user_agent = log_entry.get('user_agent', '').lower()\n            features['ua_length'] = len(user_agent)\n            features['ua_has_bot'] = 1 if any(bot in user_agent for bot in ['bot', 'crawler', 'spider']) else 0\n            features['ua_has_browser'] = 1 if any(browser in user_agent for browser in ['mozilla', 'chrome', 'safari', 'firefox']) else 0\n            features['ua_suspicious'] = 1 if any(tool in user_agent for tool in ['sqlmap', 'nikto', 'nmap', 'curl', 'python']) else 0\n            \n            # URL 패턴 분석\n            url = log_entry.get('url', '')\n            features['url_length'] = len(url)\n            features['url_params_count'] = url.count('&') + (1 if '?' in url else 0)\n            features['url_has_sql_keywords'] = 1 if any(keyword in url.lower() for keyword in ['select', 'union', 'drop', 'insert']) else 0\n            features['url_has_xss_patterns'] = 1 if any(pattern in url.lower() for pattern in ['<script', 'javascript:', 'alert(']) else 0\n            \n            # IP 기반 특성\n            client_ip = log_entry.get('client_ip', '127.0.0.1')\n            ip_parts = client_ip.split('.')\n            if len(ip_parts) == 4:\n                try:\n                    features['ip_first_octet'] = int(ip_parts[0])\n                    features['ip_is_private'] = 1 if ip_parts[0] in ['10', '172', '192'] else 0\n                except:\n                    features['ip_first_octet'] = 0\n                    features['ip_is_private'] = 0\n            else:\n                features['ip_first_octet'] = 0\n                features['ip_is_private'] = 0\n            \n            # 응답 시간\n            features['response_time'] = log_entry.get('processing_time', 0)\n            \n            return np.array(list(features.values()))\n            \n        except Exception as e:\n            logger.error(f\"API 특성 추출 실패: {e}\")\n            raise SecurityDetectionError(f\"API 특성 추출 실패: {e}\")\n    \n    def prepare_training_data(self, data_source: Union[str, pd.DataFrame] = None) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"훈련 데이터 준비\"\"\"\n        try:\n            if self.detection_type == 'api_log':\n                if isinstance(data_source, pd.DataFrame):\n                    # CICIDS2017 데이터 활용\n                    return self._prepare_cicids_data(data_source)\n                else:\n                    # 로그 파일 활용\n                    return self._prepare_log_data(data_source)\n            else:\n                # 네트워크 트래픽 데이터\n                if isinstance(data_source, np.ndarray):\n                    return data_source, np.ones(len(data_source))  # 더미 라벨\n                else:\n                    raise SecurityDetectionError(\"네트워크 트래픽 데이터는 numpy 배열이어야 합니다\")\n                    \n        except Exception as e:\n            logger.error(f\"훈련 데이터 준비 실패: {e}\")\n            raise SecurityDetectionError(f\"훈련 데이터 준비 실패: {e}\")\n    \n    def _prepare_cicids_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"CICIDS2017 데이터 전처리\"\"\"\n        # 주요 특성 선택\n        feature_columns = [\n            'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n            'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n            'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n            'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n            'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std',\n            'Fwd IAT Total', 'Fwd IAT Mean', 'Bwd IAT Total', 'Bwd IAT Mean'\n        ]\n        \n        available_columns = [col for col in feature_columns if col in df.columns]\n        X = df[available_columns].fillna(0)\n        y = (df['Label'] != 'BENIGN').astype(int)\n        \n        # 무한대 값 처리\n        X = X.replace([np.inf, -np.inf], 0)\n        \n        return X.values, y.values\n    \n    def _prepare_log_data(self, log_file_path: str) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"로그 파일 전처리\"\"\"\n        logs = []\n        labels = []\n        \n        with open(log_file_path, 'r') as f:\n            for line in f:\n                try:\n                    log_entry = json.loads(line.strip())\n                    features = self.extract_api_features(log_entry)\n                    is_suspicious = log_entry.get('is_suspicious', False)\n                    \n                    logs.append(features)\n                    labels.append(1 if is_suspicious else 0)\n                except:\n                    continue\n        \n        return np.array(logs), np.array(labels)\n    \n    def build_mlp_model(self, input_shape: int) -> keras.Model:\n        \"\"\"MLP 모델 구축\"\"\"\n        hidden_units = SecurityConfig.MLP_HIDDEN_UNITS\n        dropout_rates = SecurityConfig.DROPOUT_RATES\n        \n        model = keras.Sequential([\n            keras.layers.Input(shape=(input_shape,)),\n            keras.layers.Dense(hidden_units[0], activation='relu', name='hidden_layer_1'),\n            keras.layers.Dropout(dropout_rates[0]),\n            keras.layers.Dense(hidden_units[1], activation='relu', name='hidden_layer_2'),\n            keras.layers.Dropout(dropout_rates[1]),\n            keras.layers.Dense(hidden_units[2], activation='relu', name='hidden_layer_3'),\n            keras.layers.Dense(1, activation='sigmoid', name='output_layer')\n        ], name='MLP_Security_Detector')\n        \n        model.compile(\n            optimizer='adam',\n            loss='binary_crossentropy',\n            metrics=['accuracy', 'precision', 'recall']\n        )\n        \n        return model\n    \n    def build_cnn_model(self, input_shape: int) -> keras.Model:\n        \"\"\"CNN 모델 구축 (시계열 패턴용)\"\"\"\n        model = keras.Sequential([\n            keras.layers.Input(shape=(self.sequence_length, input_shape)),\n            keras.layers.Conv1D(64, 3, activation='relu'),\n            keras.layers.MaxPooling1D(2),\n            keras.layers.Conv1D(32, 3, activation='relu'),\n            keras.layers.GlobalAveragePooling1D(),\n            keras.layers.Dense(50, activation='relu'),\n            keras.layers.Dropout(SecurityConfig.DROPOUT_RATES[0]),\n            keras.layers.Dense(1, activation='sigmoid')\n        ], name='CNN_Security_Detector')\n        \n        model.compile(\n            optimizer='adam',\n            loss='binary_crossentropy',\n            metrics=['accuracy', 'precision', 'recall']\n        )\n        \n        return model\n    \n    def build_hybrid_model(self, input_shape: int) -> keras.Model:\n        \"\"\"하이브리드 모델: MLP + CNN 결합\"\"\"\n        # MLP 브랜치\n        mlp_input = keras.layers.Input(shape=(input_shape,), name='mlp_input')\n        mlp_dense1 = keras.layers.Dense(64, activation='relu')(mlp_input)\n        mlp_dropout1 = keras.layers.Dropout(SecurityConfig.DROPOUT_RATES[0])(mlp_dense1)\n        mlp_dense2 = keras.layers.Dense(32, activation='relu')(mlp_dropout1)\n        mlp_output = keras.layers.Dense(16, activation='relu', name='mlp_features')(mlp_dense2)\n        \n        # CNN 브랜치\n        cnn_input = keras.layers.Input(shape=(self.sequence_length, input_shape), name='cnn_input')\n        cnn_conv1 = keras.layers.Conv1D(32, 3, activation='relu')(cnn_input)\n        cnn_pool1 = keras.layers.MaxPooling1D(2)(cnn_conv1)\n        cnn_conv2 = keras.layers.Conv1D(16, 3, activation='relu')(cnn_pool1)\n        cnn_global = keras.layers.GlobalAveragePooling1D()(cnn_conv2)\n        cnn_output = keras.layers.Dense(16, activation='relu', name='cnn_features')(cnn_global)\n        \n        # 특성 융합\n        merged = keras.layers.concatenate([mlp_output, cnn_output], name='feature_fusion')\n        fusion_dense = keras.layers.Dense(32, activation='relu')(merged)\n        fusion_dropout = keras.layers.Dropout(SecurityConfig.DROPOUT_RATES[1])(fusion_dense)\n        final_output = keras.layers.Dense(1, activation='sigmoid', name='hybrid_output')(fusion_dropout)\n        \n        model = keras.Model(\n            inputs=[mlp_input, cnn_input],\n            outputs=final_output,\n            name='Hybrid_Security_Detector'\n        )\n        \n        model.compile(\n            optimizer='adam',\n            loss='binary_crossentropy',\n            metrics=['accuracy', 'precision', 'recall']\n        )\n        \n        return model\n    \n    def prepare_sequence_data(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"CNN용 시퀀스 데이터 준비\"\"\"\n        sequences = []\n        for i in range(len(X) - self.sequence_length + 1):\n            sequences.append(X[i:i + self.sequence_length])\n        return np.array(sequences)\n    \n    def train(self, X: np.ndarray, y: np.ndarray, \n              validation_split: float = None, \n              epochs: int = None):\n        \"\"\"모델 훈련\"\"\"\n        try:\n            validation_split = validation_split or SecurityConfig.VALIDATION_SPLIT\n            epochs = epochs or SecurityConfig.DEFAULT_EPOCHS\n            \n            # 데이터 스케일링\n            X_scaled = self.scaler.fit_transform(X)\n            \n            if self.model_type == 'hybrid':\n                logger.info(\"하이브리드 모델 (MLP + CNN) 훈련 시작\")\n                history = self._train_hybrid_model(X_scaled, y, validation_split, epochs)\n                \n            elif self.model_type == 'mlp':\n                logger.info(\"MLP 모델 훈련 시작\")\n                history = self._train_mlp_model(X_scaled, y, validation_split, epochs)\n                \n            elif self.model_type == 'cnn':\n                logger.info(\"CNN 모델 훈련 시작\")\n                history = self._train_cnn_model(X_scaled, y, validation_split, epochs)\n                \n            else:\n                raise SecurityDetectionError(f\"지원하지 않는 모델 타입: {self.model_type}\")\n            \n            self.is_trained = True\n            logger.info(\"모델 훈련 완료\")\n            return history\n            \n        except Exception as e:\n            logger.error(f\"모델 훈련 실패: {e}\")\n            raise SecurityDetectionError(f\"모델 훈련 실패: {e}\")\n    \n    def _train_hybrid_model(self, X_scaled: np.ndarray, y: np.ndarray, \n                           validation_split: float, epochs: int):\n        \"\"\"하이브리드 모델 훈련\"\"\"\n        # 시퀀스 데이터 준비\n        X_sequence = self.prepare_sequence_data(X_scaled)\n        y_sequence = y[self.sequence_length-1:]\n        X_individual = X_scaled[self.sequence_length-1:]\n        \n        # 분할\n        split_idx = int(len(X_sequence) * (1 - validation_split))\n        X_seq_train, X_seq_val = X_sequence[:split_idx], X_sequence[split_idx:]\n        X_ind_train, X_ind_val = X_individual[:split_idx], X_individual[split_idx:]\n        y_train, y_val = y_sequence[:split_idx], y_sequence[split_idx:]\n        \n        # 모델 구축 및 훈련\n        self.ensemble_model = self.build_hybrid_model(X_scaled.shape[1])\n        \n        history = self.ensemble_model.fit(\n            [X_ind_train, X_seq_train], y_train,\n            validation_data=([X_ind_val, X_seq_val], y_val),\n            epochs=epochs,\n            batch_size=SecurityConfig.BATCH_SIZE,\n            callbacks=[\n                keras.callbacks.EarlyStopping(\n                    monitor='val_loss', \n                    patience=SecurityConfig.EARLY_STOPPING_PATIENCE, \n                    restore_best_weights=True\n                ),\n                keras.callbacks.ReduceLROnPlateau(\n                    monitor='val_loss', \n                    factor=0.5, \n                    patience=SecurityConfig.LEARNING_RATE_PATIENCE\n                )\n            ],\n            verbose=1\n        )\n        \n        return history\n    \n    def _train_mlp_model(self, X_scaled: np.ndarray, y: np.ndarray,\n                        validation_split: float, epochs: int):\n        \"\"\"MLP 모델 훈련\"\"\"\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_scaled, y, \n            test_size=validation_split, \n            random_state=SecurityConfig.RANDOM_SEED, \n            stratify=y\n        )\n        \n        self.mlp_model = self.build_mlp_model(X_scaled.shape[1])\n        \n        history = self.mlp_model.fit(\n            X_train, y_train,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=SecurityConfig.BATCH_SIZE,\n            callbacks=[\n                keras.callbacks.EarlyStopping(\n                    monitor='val_loss', \n                    patience=SecurityConfig.EARLY_STOPPING_PATIENCE, \n                    restore_best_weights=True\n                )\n            ],\n            verbose=1\n        )\n        \n        return history\n    \n    def _train_cnn_model(self, X_scaled: np.ndarray, y: np.ndarray,\n                        validation_split: float, epochs: int):\n        \"\"\"CNN 모델 훈련\"\"\"\n        X_sequence = self.prepare_sequence_data(X_scaled)\n        y_sequence = y[self.sequence_length-1:]\n        \n        X_train, X_val, y_train, y_val = train_test_split(\n            X_sequence, y_sequence, \n            test_size=validation_split, \n            random_state=SecurityConfig.RANDOM_SEED, \n            stratify=y_sequence\n        )\n        \n        self.cnn_model = self.build_cnn_model(X_scaled.shape[1])\n        \n        history = self.cnn_model.fit(\n            X_train, y_train,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=SecurityConfig.BATCH_SIZE,\n            callbacks=[\n                keras.callbacks.EarlyStopping(\n                    monitor='val_loss', \n                    patience=SecurityConfig.EARLY_STOPPING_PATIENCE, \n                    restore_best_weights=True\n                )\n            ],\n            verbose=1\n        )\n        \n        return history\n    \n    def predict(self, data_input: Union[Dict, np.ndarray], data_id: str = None) -> Tuple[float, bool]:\n        \"\"\"예측 수행\"\"\"\n        try:\n            if not self.is_trained and not self.general_model:\n                raise SecurityDetectionError(\"모델이 훈련되지 않았습니다\")\n            \n            if self.detection_type == 'api_log':\n                return self._predict_api_log(data_input)\n            else:\n                return self._predict_network_traffic(data_input, data_id)\n                \n        except Exception as e:\n            logger.error(f\"예측 실패: {e}\")\n            raise SecurityDetectionError(f\"예측 실패: {e}\")\n    \n    def _predict_api_log(self, log_entry: Dict) -> Tuple[float, bool]:\n        \"\"\"API 로그 예측\"\"\"\n        features = self.extract_api_features(log_entry)\n        features_scaled = self.scaler.transform([features])\n        \n        if self.model_type == 'hybrid' and self.ensemble_model:\n            dummy_sequence = np.repeat(features_scaled, self.sequence_length, axis=0).reshape(1, self.sequence_length, -1)\n            probability = self.ensemble_model.predict([features_scaled, dummy_sequence], verbose=0)[0][0]\n        elif self.model_type == 'mlp' and self.mlp_model:\n            probability = self.mlp_model.predict(features_scaled, verbose=0)[0][0]\n        elif self.model_type == 'cnn' and self.cnn_model:\n            dummy_sequence = np.repeat(features_scaled, self.sequence_length, axis=0).reshape(1, self.sequence_length, -1)\n            probability = self.cnn_model.predict(dummy_sequence, verbose=0)[0][0]\n        else:\n            probability = np.random.uniform(0.1, 0.3)  # 폴백\n        \n        is_anomaly = probability > 0.5\n        return float(probability), is_anomaly\n    \n    def _predict_network_traffic(self, packet_features: np.ndarray, packet_id: str = None) -> Tuple[float, bool]:\n        \"\"\"네트워크 트래픽 예측\"\"\"\n        # 특성 정규화\n        if self.scaler:\n            packet_features = self.scaler.transform(packet_features.reshape(1, -1))\n        else:\n            packet_features = packet_features.reshape(1, -1)\n        \n        # 예측 수행\n        try:\n            if hasattr(self.general_model, 'predict'):\n                prediction = self.general_model.predict(packet_features, verbose=0)[0][0]\n            else:\n                prediction = np.random.uniform(0, 1)  # 폴백\n        except:\n            prediction = np.random.uniform(0, 1)  # 오류 시 폴백\n        \n        is_attack = prediction > 0.5\n        confidence = prediction if is_attack else 1 - prediction\n        \n        # 탐지 결과 기록\n        detection_result = {\n            'packet_id': packet_id or len(self.detection_history) + 1,\n            'timestamp': time.time(),\n            'prediction': prediction,\n            'is_attack': is_attack,\n            'confidence': confidence,\n            'features': packet_features.flatten()\n        }\n        \n        self.detection_history.append(detection_result)\n        \n        if is_attack:\n            self.alert_count += 1\n        \n        return float(prediction), is_attack\n    \n    def save_model(self, model_path: str = \"models/unified_detector\"):\n        \"\"\"모델 저장\"\"\"\n        try:\n            import os\n            os.makedirs(os.path.dirname(model_path), exist_ok=True)\n            \n            # 각 모델별로 저장\n            if self.ensemble_model:\n                self.ensemble_model.save(f\"{model_path}_hybrid.keras\")\n            if self.mlp_model:\n                self.mlp_model.save(f\"{model_path}_mlp.keras\")\n            if self.cnn_model:\n                self.cnn_model.save(f\"{model_path}_cnn.keras\")\n            \n            # 스케일러 저장\n            joblib.dump(self.scaler, f\"{model_path}_scaler.pkl\")\n            \n            # 메타데이터 저장\n            metadata = {\n                \"detection_type\": self.detection_type,\n                \"model_type\": self.model_type,\n                \"is_trained\": self.is_trained,\n                \"sequence_length\": self.sequence_length\n            }\n            with open(f\"{model_path}_metadata.json\", 'w') as f:\n                json.dump(metadata, f)\n            \n            logger.info(f\"모델 저장 완료: {model_path}\")\n            \n        except Exception as e:\n            logger.error(f\"모델 저장 실패: {e}\")\n            raise SecurityDetectionError(f\"모델 저장 실패: {e}\")\n    \n    def load_model(self, model_path: str = \"models/unified_detector\"):\n        \"\"\"모델 로드\"\"\"\n        try:\n            # 메타데이터 로드\n            with open(f\"{model_path}_metadata.json\", 'r') as f:\n                metadata = json.load(f)\n            \n            self.detection_type = metadata[\"detection_type\"]\n            self.model_type = metadata[\"model_type\"]\n            self.is_trained = metadata[\"is_trained\"]\n            self.sequence_length = metadata.get(\"sequence_length\", SecurityConfig.CNN_SEQUENCE_LENGTH)\n            \n            # 각 모델 로드 시도\n            try:\n                self.ensemble_model = keras.models.load_model(f\"{model_path}_hybrid.keras\")\n                logger.info(\"하이브리드 모델 로드 완료\")\n            except:\n                pass\n            \n            try:\n                self.mlp_model = keras.models.load_model(f\"{model_path}_mlp.keras\")\n                logger.info(\"MLP 모델 로드 완료\")\n            except:\n                pass\n            \n            try:\n                self.cnn_model = keras.models.load_model(f\"{model_path}_cnn.keras\")\n                logger.info(\"CNN 모델 로드 완료\")\n            except:\n                pass\n            \n            # 스케일러 로드\n            self.scaler = joblib.load(f\"{model_path}_scaler.pkl\")\n            \n            logger.info(\"통합 탐지 엔진 로드 완료\")\n            \n        except Exception as e:\n            logger.error(f\"모델 로드 실패: {e}\")\n            raise SecurityDetectionError(f\"모델 로드 실패: {e}\")\n    \n    def get_detection_stats(self) -> Dict:\n        \"\"\"탐지 통계 반환\"\"\"\n        if not self.detection_history:\n            return {\n                'total_detections': 0,\n                'attack_detections': 0,\n                'attack_ratio': 0.0,\n                'avg_confidence': 0.0,\n                'recent_attack_rate': 0.0\n            }\n        \n        total_detections = len(self.detection_history)\n        attack_detections = sum(1 for r in self.detection_history if r.get('is_attack', False))\n        attack_ratio = attack_detections / total_detections * 100\n        \n        # 신뢰도 계산 (네트워크 트래픽의 경우)\n        if 'confidence' in self.detection_history[0]:\n            avg_confidence = np.mean([r['confidence'] for r in self.detection_history])\n        else:\n            avg_confidence = 0.0\n        \n        # 최근 100개의 공격 비율\n        recent_results = self.detection_history[-100:]\n        recent_attacks = sum(1 for r in recent_results if r.get('is_attack', False))\n        recent_attack_rate = recent_attacks / len(recent_results) * 100\n        \n        return {\n            'total_detections': total_detections,\n            'attack_detections': attack_detections,\n            'attack_ratio': attack_ratio,\n            'avg_confidence': avg_confidence,\n            'recent_attack_rate': recent_attack_rate,\n            'detection_type': self.detection_type,\n            'model_type': self.model_type\n        }\n    \n    def clear_history(self):\n        \"\"\"탐지 이력 초기화\"\"\"\n        self.detection_history = []\n        self.alert_count = 0\n        logger.info(\"탐지 이력 초기화 완료\")\n\n\nclass RealTimeSecurityMonitor:\n    \"\"\"실시간 보안 모니터링 시스템\"\"\"\n    \n    def __init__(self, detection_engine: UnifiedDetectionEngine):\n        self.detection_engine = detection_engine\n        self.alert_threshold = SecurityConfig.ALERT_THRESHOLD\n        self.recent_alerts = []\n        self.max_recent_count = SecurityConfig.MAX_RECENT_ANOMALIES\n        \n        logger.info(\"실시간 보안 모니터 초기화 완료\")\n    \n    def process_data(self, data_input: Union[Dict, np.ndarray], data_id: str = None) -> Dict:\n        \"\"\"데이터 실시간 처리\"\"\"\n        try:\n            probability, is_threat = self.detection_engine.predict(data_input, data_id)\n            \n            result = {\n                \"timestamp\": datetime.now().isoformat(),\n                \"data_id\": data_id,\n                \"threat_probability\": probability,\n                \"is_threat\": is_threat,\n                \"alert_level\": self._get_alert_level(probability),\n                \"detection_type\": self.detection_engine.detection_type\n            }\n            \n            # API 로그의 경우 추가 정보\n            if isinstance(data_input, dict):\n                result.update({\n                    \"client_ip\": data_input.get(\"client_ip\"),\n                    \"method\": data_input.get(\"method\"),\n                    \"url\": data_input.get(\"url\")\n                })\n            \n            # 고위험 탐지 시 알림\n            if probability > self.alert_threshold:\n                self._trigger_alert(data_input, result)\n            \n            # 최근 알림 기록 업데이트\n            if is_threat:\n                self.recent_alerts.append(result)\n                if len(self.recent_alerts) > self.max_recent_count:\n                    self.recent_alerts.pop(0)\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"실시간 처리 오류: {e}\")\n            return {\"error\": str(e)}\n    \n    def _get_alert_level(self, probability: float) -> str:\n        \"\"\"위험도 레벨 결정\"\"\"\n        for level, threshold in SecurityConfig.RISK_THRESHOLDS.items():\n            if probability >= threshold:\n                return level\n        return \"LOW\"\n    \n    def _trigger_alert(self, data_input: Union[Dict, np.ndarray], detection_result: Dict):\n        \"\"\"알림 발송\"\"\"\n        alert_message = {\n            \"alert_type\": f\"{self.detection_engine.detection_type.upper()}_THREAT_DETECTED\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"threat_probability\": detection_result[\"threat_probability\"],\n            \"alert_level\": detection_result[\"alert_level\"],\n            \"detection_details\": detection_result\n        }\n        \n        # 로그에 기록\n        logger.warning(f\"SECURITY ALERT: {json.dumps(alert_message)}\")\n    \n    def get_monitoring_statistics(self) -> Dict:\n        \"\"\"모니터링 통계\"\"\"\n        total_recent = len(self.recent_alerts)\n        if total_recent == 0:\n            return {\"message\": \"최근 위협 탐지 없음\"}\n        \n        high_risk_count = sum(1 for a in self.recent_alerts if a[\"alert_level\"] in [\"HIGH\", \"CRITICAL\"])\n        avg_probability = np.mean([a[\"threat_probability\"] for a in self.recent_alerts])\n        \n        # 탐지 엔진 통계와 결합\n        engine_stats = self.detection_engine.get_detection_stats()\n        \n        return {\n            \"recent_threats_count\": total_recent,\n            \"high_risk_count\": high_risk_count,\n            \"average_threat_probability\": round(avg_probability, 3),\n            \"risk_ratio\": round(high_risk_count / total_recent, 3) if total_recent > 0 else 0,\n            \"engine_stats\": engine_stats,\n            \"monitor_settings\": {\n                \"alert_threshold\": self.alert_threshold,\n                \"max_recent_count\": self.max_recent_count\n            }\n        }\n\n\nclass TrafficSimulator:\n    \"\"\"네트워크 트래픽 시뮬레이터 (기존 기능 유지)\"\"\"\n    \n    def __init__(self, seed: int = None):\n        seed = seed or SecurityConfig.RANDOM_SEED\n        np.random.seed(seed)\n        random.seed(seed)\n        logger.info(f\"트래픽 시뮬레이터 초기화: seed={seed}\")\n    \n    def generate_normal_traffic(self, n_packets: int) -> np.ndarray:\n        \"\"\"정상 트래픽 생성\"\"\"\n        return np.random.normal(0, 1, (n_packets, 19))\n    \n    def generate_attack_traffic(self, attack_type: str, n_packets: int) -> np.ndarray:\n        \"\"\"공격 트래픽 생성\"\"\"\n        data = np.random.normal(0, 1, (n_packets, 19))\n        \n        if attack_type == \"ddos\":\n            data[:, 0] *= 10  # Flow_Bytes/s 증가\n            data[:, 1] *= 5   # Flow_Packets/s 증가\n            data[:, 2] /= 3   # Backward_Packets 감소\n        elif attack_type == \"web_attack\":\n            data[:, 3] *= 3   # 패킷 길이 증가\n            data[:, 4] *= 2   # 전송 패킷 길이 증가\n        elif attack_type == \"brute_force\":\n            data[:, 5] /= 5   # IAT 감소\n            data[:, 6] *= 3   # 패킷 수 증가\n        elif attack_type == \"port_scan\":\n            data[:, 1] *= 2   # Forward 패킷 증가\n            data[:, 2] /= 4   # Backward 패킷 감소\n        \n        return data\n    \n    def generate_mixed_traffic(self, n_packets: int, attack_ratio: float = 0.3) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"혼합 트래픽 생성 (라벨 포함)\"\"\"\n        n_normal = int(n_packets * (1 - attack_ratio))\n        n_attack = n_packets - n_normal\n        \n        normal_traffic = self.generate_normal_traffic(n_normal)\n        normal_labels = np.zeros(n_normal)\n        \n        attack_types = [\"ddos\", \"web_attack\", \"brute_force\", \"port_scan\"]\n        attack_per_type = n_attack // len(attack_types)\n        remainder = n_attack % len(attack_types)\n        \n        attack_traffic_list = []\n        attack_labels_list = []\n        \n        for i, attack_type in enumerate(attack_types):\n            n_this_attack = attack_per_type + (1 if i < remainder else 0)\n            if n_this_attack > 0:\n                attack_data = self.generate_attack_traffic(attack_type, n_this_attack)\n                attack_traffic_list.append(attack_data)\n                attack_labels_list.append(np.ones(n_this_attack))\n        \n        if attack_traffic_list:\n            all_attack_traffic = np.vstack(attack_traffic_list)\n            all_attack_labels = np.concatenate(attack_labels_list)\n            \n            all_traffic = np.vstack([normal_traffic, all_attack_traffic])\n            all_labels = np.concatenate([normal_labels, all_attack_labels])\n        else:\n            all_traffic = normal_traffic\n            all_labels = normal_labels\n        \n        # 무작위로 섞기\n        indices = np.random.permutation(len(all_traffic))\n        return all_traffic[indices], all_labels[indices]\n\n\nclass PerformanceEvaluator:\n    \"\"\"성능 평가 시스템\"\"\"\n    \n    def __init__(self):\n        self.evaluation_history = []\n        logger.info(\"성능 평가기 초기화 완료\")\n    \n    def evaluate_detection_performance(self, true_labels: np.ndarray, \n                                     predicted_labels: np.ndarray, \n                                     prediction_scores: np.ndarray = None) -> Dict:\n        \"\"\"탐지 성능 평가\"\"\"\n        try:\n            metrics = {\n                'accuracy': accuracy_score(true_labels, predicted_labels),\n                'precision': precision_score(true_labels, predicted_labels, zero_division=0),\n                'recall': recall_score(true_labels, predicted_labels, zero_division=0),\n                'f1_score': f1_score(true_labels, predicted_labels, zero_division=0)\n            }\n            \n            # AUC 계산\n            if prediction_scores is not None:\n                try:\n                    metrics['auc'] = roc_auc_score(true_labels, prediction_scores)\n                except:\n                    metrics['auc'] = 0.5\n            \n            # 혼동 행렬\n            cm = confusion_matrix(true_labels, predicted_labels)\n            if cm.shape == (2, 2):\n                tn, fp, fn, tp = cm.ravel()\n                metrics.update({\n                    'true_negatives': int(tn),\n                    'false_positives': int(fp),\n                    'false_negatives': int(fn),\n                    'true_positives': int(tp),\n                    'false_positive_rate': fp / (fp + tn) if (fp + tn) > 0 else 0,\n                    'false_negative_rate': fn / (fn + tp) if (fn + tp) > 0 else 0\n                })\n            \n            # 평가 이력에 추가\n            evaluation_record = {\n                'timestamp': datetime.now().isoformat(),\n                'metrics': metrics,\n                'sample_count': len(true_labels)\n            }\n            self.evaluation_history.append(evaluation_record)\n            \n            logger.info(f\"성능 평가 완료: Accuracy={metrics['accuracy']:.3f}, F1={metrics['f1_score']:.3f}\")\n            return metrics\n            \n        except Exception as e:\n            logger.error(f\"성능 평가 실패: {e}\")\n            raise SecurityDetectionError(f\"성능 평가 실패: {e}\")\n    \n    def generate_performance_report(self, detection_results: List[Dict], \n                                  true_labels: np.ndarray = None) -> Dict:\n        \"\"\"성능 보고서 생성\"\"\"\n        if not detection_results:\n            return {\"error\": \"탐지 결과가 없습니다\"}\n        \n        total_detections = len(detection_results)\n        threat_predictions = sum(1 for r in detection_results if r.get('is_threat', r.get('is_attack', False)))\n        threat_ratio = threat_predictions / total_detections * 100\n        \n        report = {\n            'basic_stats': {\n                'total_detections': total_detections,\n                'predicted_threats': threat_predictions,\n                'threat_ratio': threat_ratio,\n                'evaluation_timestamp': datetime.now().isoformat()\n            }\n        }\n        \n        # 실제 라벨이 있는 경우 정확도 계산\n        if true_labels is not None and len(true_labels) == total_detections:\n            predicted_labels = [r.get('is_threat', r.get('is_attack', False)) for r in detection_results]\n            prediction_scores = [r.get('threat_probability', r.get('prediction', 0)) for r in detection_results]\n            \n            performance = self.evaluate_detection_performance(\n                true_labels, predicted_labels, prediction_scores\n            )\n            report['performance'] = performance\n        \n        return report\n\n\n# 편의 함수들\ndef create_api_log_detector(model_type: str = 'hybrid') -> UnifiedDetectionEngine:\n    \"\"\"API 로그 탐지기 생성\"\"\"\n    return UnifiedDetectionEngine(detection_type='api_log', model_type=model_type)\n\ndef create_network_traffic_detector() -> UnifiedDetectionEngine:\n    \"\"\"네트워크 트래픽 탐지기 생성\"\"\"\n    return UnifiedDetectionEngine(detection_type='network_traffic', model_type='general')\n\ndef create_security_monitor(detection_engine: UnifiedDetectionEngine) -> RealTimeSecurityMonitor:\n    \"\"\"보안 모니터 생성\"\"\"\n    return RealTimeSecurityMonitor(detection_engine)\n\n\nif __name__ == \"__main__\":\n    # 테스트 코드\n    logger.info(\"통합 보안 탐지 엔진 테스트 시작\")\n    \n    # API 로그 탐지기 테스트\n    api_detector = create_api_log_detector('hybrid')\n    api_monitor = create_security_monitor(api_detector)\n    \n    # 네트워크 트래픽 탐지기 테스트\n    network_detector = create_network_traffic_detector()\n    network_monitor = create_security_monitor(network_detector)\n    \n    logger.info(\"통합 보안 탐지 엔진 테스트 완료\")\n
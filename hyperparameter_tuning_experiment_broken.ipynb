{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 딥러닝 하이퍼파라미터 튜닝 실습\\n",
    "\\n",
    "**목적:** '혼자 공부하는 머신러닝, 딥러닝' 방식을 딥러닝에 적용\\n",
    "**데이터:** Mall Customer Segmentation 데이터\\n",
    "**모델:** 분류 신경망 (Classification Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\\n",
    "import sys\\n",
    "import os\\n",
    "\\n",
    "# 프로젝트 루트 디렉토리를 Python path에 추가\\n",
    "project_root = os.path.dirname(os.getcwd())\\n",
    "if project_root not in sys.path:\\n",
    "    sys.path.append(project_root)\\n",
    "\\n",
    "from core.hyperparameter_tuning import HyperparameterTuner, run_grid_search_experiment\\n",
    "import pandas as pd\\n",
    "import matplotlib.pyplot as plt\\n",
    "import numpy as np\\n",
    "\\n",
    "# TensorFlow 경고 줄이기\\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\\n",
    "\\n",
    "print(\\"🎯 하이퍼파라미터 튜닝 환경 준비 완료!\\")\\n",
    "print(\\"📊 사용할 데이터: Mall Customer Segmentation\\")\\n",
    "print(\\"🧠 테스트할 모델: 분류 신경망\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 실험 1: 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜너 인스턴스 생성\\n",
    "tuner = HyperparameterTuner()\\n",
    "\\n",
    "# 데이터 로드 및 전처리\\n",
    "X_train, X_test, y_train, y_test = tuner.prepare_data()\\n",
    "\\n",
    "print(f\\"훈련 데이터 크기: {X_train.shape}\\")\\n",
    "print(f\\"테스트 데이터 크기: {X_test.shape}\\")\\n",
    "print(f\\"클러스터 수: {len(np.unique(y_train))}\\")\\n",
    "print(f\\"특성 수: {X_train.shape[1]}\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 실험 2: Learning Rate 튜닝\\n",
    "\\n",
    "**가설:** 학습률이 너무 높으면 발산하고, 너무 낮으면 학습이 느려질 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 튜닝 실행\\n",
    "best_lr, lr_results = tuner.tune_learning_rate(X_train, y_train, X_test, y_test)\\n",
    "\\n",
    "# 결과 시각화\\n",
    "if lr_results:\\n",
    "    lr_df = pd.DataFrame(lr_results)\\n",
    "    \\n",
    "    plt.figure(figsize=(10, 6))\\n",
    "    plt.subplot(1, 2, 1)\\n",
    "    plt.bar([str(lr) for lr in lr_df['learning_rate']], lr_df['val_accuracy'])\\n",
    "    plt.title('Learning Rate vs Validation Accuracy')\\n",
    "    plt.xlabel('Learning Rate')\\n",
    "    plt.ylabel('Validation Accuracy')\\n",
    "    plt.xticks(rotation=45)\\n",
    "    \\n",
    "    # 최고 성능 강조\\n",
    "    best_idx = lr_df['val_accuracy'].idxmax()\\n",
    "    plt.bar(str(lr_df.loc[best_idx, 'learning_rate']), lr_df.loc[best_idx, 'val_accuracy'], color='red', alpha=0.7)\\n",
    "    \\n",
    "    plt.tight_layout()\\n",
    "    plt.show()\\n",
    "    \\n",
    "    print(f\\"🎯 최적 학습률: {best_lr}\\")\\n",
    "    display(lr_df[['learning_rate', 'val_accuracy']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 실험 3: Hidden Units 튜닝\\n",
    "\\n",
    "**가설:** 뉴런이 너무 적으면 underfitting, 너무 많으면 overfitting이 발생할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 크기 튜닝 실행 (최적 학습률 사용)\\n",
    "best_units, units_results = tuner.tune_hidden_units(X_train, y_train, X_test, y_test, best_lr)\\n",
    "\\n",
    "# 결과 시각화\\n",
    "if units_results:\\n",
    "    units_df = pd.DataFrame(units_results)\\n",
    "    \\n",
    "    plt.figure(figsize=(10, 6))\\n",
    "    plt.plot(units_df['hidden_units'], units_df['val_accuracy'], 'bo-', linewidth=2, markersize=8)\\n",
    "    plt.title('Hidden Units vs Validation Accuracy')\\n",
    "    plt.xlabel('Number of Hidden Units')\\n",
    "    plt.ylabel('Validation Accuracy')\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    # 최고 성능 포인트 강조\\n",
    "    best_idx = units_df['val_accuracy'].idxmax()\\n",
    "    plt.plot(units_df.loc[best_idx, 'hidden_units'], units_df.loc[best_idx, 'val_accuracy'], 'ro', markersize=12)\\n",
    "    \\n",
    "    plt.show()\\n",
    "    \\n",
    "    print(f\\"🎯 최적 은닉층 크기: {best_units}\\")\\n",
    "    display(units_df[['hidden_units', 'val_accuracy']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 실험 4: Dropout Rate 튜닝\\n",
    "\\n",
    "**가설:** 적절한 드롭아웃은 과적합을 방지하면서 성능을 유지할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃 비율 튜닝 실행\\n",
    "best_dropout, dropout_results = tuner.tune_dropout_rate(X_train, y_train, X_test, y_test, best_lr, best_units)\\n",
    "\\n",
    "# 결과 시각화\\n",
    "if dropout_results:\\n",
    "    dropout_df = pd.DataFrame(dropout_results)\\n",
    "    \\n",
    "    plt.figure(figsize=(12, 8))\\n",
    "    \\n",
    "    # 검증 정확도 그래프\\n",
    "    plt.subplot(2, 2, 1)\\n",
    "    plt.plot(dropout_df['dropout_rate'], dropout_df['val_accuracy'], 'go-', linewidth=2, markersize=8)\\n",
    "    plt.title('Dropout Rate vs Validation Accuracy')\\n",
    "    plt.xlabel('Dropout Rate')\\n",
    "    plt.ylabel('Validation Accuracy')\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    # 과적합 갭 그래프\\n",
    "    plt.subplot(2, 2, 2)\\n",
    "    plt.plot(dropout_df['dropout_rate'], dropout_df['overfitting_gap'], 'ro-', linewidth=2, markersize=8)\\n",
    "    plt.title('Dropout Rate vs Overfitting Gap')\\n",
    "    plt.xlabel('Dropout Rate')\\n",
    "    plt.ylabel('Overfitting Gap (Train - Val)')\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    # 훈련 vs 검증 정확도 비교\\n",
    "    plt.subplot(2, 2, 3)\\n",
    "    plt.plot(dropout_df['dropout_rate'], dropout_df['train_accuracy'], 'b-', label='Train Accuracy', linewidth=2)\\n",
    "    plt.plot(dropout_df['dropout_rate'], dropout_df['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)\\n",
    "    plt.title('Train vs Validation Accuracy')\\n",
    "    plt.xlabel('Dropout Rate')\\n",
    "    plt.ylabel('Accuracy')\\n",
    "    plt.legend()\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    plt.tight_layout()\\n",
    "    plt.show()\\n",
    "    \\n",
    "    print(f\\"🎯 최적 드롭아웃 비율: {best_dropout}\\")\\n",
    "    display(dropout_df[['dropout_rate', 'val_accuracy', 'train_accuracy', 'overfitting_gap']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 실험 5: 최종 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 하이퍼파라미터로 최종 모델 훈련\\n",
    "final_model, final_history = tuner.final_validation(\\n",
    "    X_train, y_train, X_test, y_test, \\n",
    "    best_lr, best_units, best_dropout\\n",
    ")\\n",
    "\\n",
    "if final_model and final_history:\\n",
    "    # 훈련 과정 시각화\\n",
    "    plt.figure(figsize=(12, 5))\\n",
    "    \\n",
    "    # 정확도 그래프\\n",
    "    plt.subplot(1, 2, 1)\\n",
    "    epochs = range(1, len(final_history.history['accuracy']) + 1)\\n",
    "    plt.plot(epochs, final_history.history['accuracy'], 'b-', label='Training Accuracy')\\n",
    "    plt.plot(epochs, final_history.history['val_accuracy'], 'r-', label='Validation Accuracy')\\n",
    "    plt.title('Training and Validation Accuracy')\\n",
    "    plt.xlabel('Epochs')\\n",
    "    plt.ylabel('Accuracy')\\n",
    "    plt.legend()\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    # 손실 그래프\\n",
    "    plt.subplot(1, 2, 2)\\n",
    "    plt.plot(epochs, final_history.history['loss'], 'b-', label='Training Loss')\\n",
    "    plt.plot(epochs, final_history.history['val_loss'], 'r-', label='Validation Loss')\\n",
    "    plt.title('Training and Validation Loss')\\n",
    "    plt.xlabel('Epochs')\\n",
    "    plt.ylabel('Loss')\\n",
    "    plt.legend()\\n",
    "    plt.grid(True, alpha=0.3)\\n",
    "    \\n",
    "    plt.tight_layout()\\n",
    "    plt.show()\\n",
    "    \\n",
    "    # 최종 성능 평가\\n",
    "    test_loss, test_accuracy = final_model.evaluate(X_test, y_test, verbose=0)\\n",
    "    \\n",
    "    print(\\"\\\\n🏆 최종 결과 요약:\\")\\n",
    "    print(f\\"- 최적 Learning Rate: {best_lr}\\")\\n",
    "    print(f\\"- 최적 Hidden Units: {best_units}\\")\\n",
    "    print(f\\"- 최적 Dropout Rate: {best_dropout}\\")\\n",
    "    print(f\\"- 최종 테스트 정확도: {test_accuracy:.4f}\\")\\n",
    "    print(f\\"- 최종 테스트 손실: {test_loss:.4f}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 보너스: 그리드 서치 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치 방식으로 모든 조합 테스트\\n",
    "print(\\"🔍 그리드 서치 실험 시작...\\")\\n",
    "grid_best, grid_results_df = run_grid_search_experiment(limited_combinations=True)\\n",
    "\\n",
    "if grid_results_df is not None:\\n",
    "    # 결과 히트맵 그리기\\n",
    "    import seaborn as sns\\n",
    "    \\n",
    "    # Learning Rate와 Hidden Units에 대한 히트맵\\n",
    "    pivot_table = grid_results_df.pivot_table(\\n",
    "        values='val_accuracy', \\n",
    "        index='hidden_units', \\n",
    "        columns='learning_rate', \\n",
    "        aggfunc='mean'\\n",
    "    )\\n",
    "    \\n",
    "    plt.figure(figsize=(8, 6))\\n",
    "    sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='viridis')\\n",
    "    plt.title('Validation Accuracy Heatmap\\\\n(Learning Rate vs Hidden Units)')\\n",
    "    plt.show()\\n",
    "    \\n",
    "    print(\\"🏆 그리드 서치 vs 단계별 튜닝 비교:\\")\\n",
    "    print(f\\"단계별 튜닝 결과: lr={best_lr}, units={best_units}, dropout={best_dropout}\\")\\n",
    "    print(f\\"그리드 서치 결과: lr={grid_best['learning_rate']}, units={grid_best['hidden_units']}, dropout={grid_best['dropout_rate']}\\")\\n",
    "    print(f\\"성능 차이: {abs(grid_best['val_accuracy'] - test_accuracy):.4f}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 학습 정리\\n",
    "\\n",
    "### 배운 것들:\\n",
    "1. **Learning Rate의 중요성**: 가장 큰 영향을 미치는 하이퍼파라미터\\n",
    "2. **Network Size**: 적절한 크기가 중요 (너무 크면 overfitting, 너무 작으면 underfitting)\\n",
    "3. **Dropout의 효과**: 과적합 방지에 효과적\\n",
    "4. **단계별 접근법**: 체계적인 튜닝이 무작위 탐색보다 효율적\\n",
    "\\n",
    "### 실무 적용:\\n",
    "- Early Stopping으로 시간 절약\\n",
    "- 검증 세트 기준으로 선택\\n",
    "- 과적합 갭 모니터링\\n",
    "- 재현 가능한 실험 설계"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}